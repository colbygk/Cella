\section{Results} \label{results}

For the results reported here, the CA population is 100, selection is tournament with elitism, offspring CA populations are created with both 
mutation and crossover, the IC length is 121, the size of the IC test set is 100, and CAs are run for a maximum of 
200 iterations per IC over 50 generations. When rules are referred to using decimal notation, the encoding follows Mitchell 
\cite{Mitchell:1994:ECA:186092.186116}. See section \ref{sec:methods} 
for more information regarding methods.

\subsection{Comparing neighborhoods} \label{sec:2_1}
Our first goal was to compare rules with different neighborhoods. In particular, there is a tradeoff between the size of the search space and the 
the amount of information available for purposes of setting a location state. Larger neighborhoods have rules that can 'see' more of the source IC, and 
hence (intuitively) make a more informed decision about how to set the output bit, but this comes at a cost of increasing the size of the search space by multiple 
orders of magnitude ($2^{32}$ vs. $2^{128}$).

Figure~\ref{fig:waterfall} shows two typical CA runs on the same IC. Rule XXXX (left) has such-and-such properties, while rule YYYY is an example of a rule that successfully categorizes the IC within 200 iterations.
\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{foo.png}
\caption{Waterfall plots of two typical CA runs on the same IC. The top row is the IC, and each successive row is the result of applying the CA rule 
to the preceding row. The left hand figure depicts rule XXXX, which fails to converge within 200 iterations; the right hand figure depicts rule YYYY, 
which correctly categorizes the density of \texttt{1}s in the IC by converging to all \texttt{1}s.}
\label{fig:waterfall}
\end{center}
\end{figure}

Figures~\ref{fig:r2_rho} and \ref{fig:r3_rho} plot the performance of an elite $r = 2$ and an elite $r = 3$ rule, respectively, as evolved after 50 generations. As can be seen, performance did not differ significantly; or maybe it did. We'll find out, and put a summary regarding which rule performs better here.

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{foo.png}
\caption{Performance of an elite, $r = 2$ rule as a function of $\rho$. Rule ZZZZ was tested against multiple ICs (when possible), and the precent correct is plotted on the \textit{y}-axis. As expected, the rule performs well when the proportion of \texttt{1}s is 
low or high, but performance drops as $\rho$ approaches the difficult cases around $\frac{1}{2}$.}
\label{fig:r2_rho}
\end{center}
\end{figure}
\begin{figure} [ht]
\begin{center}
\includegraphics[width=\linewidth]{foo.png}
\caption{Performance of an elite, $r = 3$ rule as a function of $\rho$. As in the case of an elite $r = 2$ rule (fig.~\ref{fig:r2_rho}), the rule performs well when the proportion of \texttt{1}s is 
low or high, but performance drops as $\rho$ approaches the difficult cases around $\frac{1}{2}$.}
\label{fig:r3_rho}
\end{center}
\end{figure}

It is also interesting to compare the performance of the most fit $r = 2$ and $r = 3$ rules over multiple generations. Figures~\ref{fig:r2_best_fit} and 
\ref{fig:r3_best_fit} show the best fitness for the two neighborhoods as a function of generation. As can be seen in those figures, both trajectories exhibit 
`epochs' as described by Mitchell \cite{Mitchell:1994:ECA:186092.186116}: There is an initial plateau interrupted by a jagged rise in best fitness, where 
these increases represent the discovery of new, dominant strategies. However, as can also be seen from the figures, the $r = 2$ population discovers later epochs sooner than the $r = 3$ population - or maybe they don't, or maybe it's the other way around.

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{foo.png}
\caption{Best fitness for $r = 2$ CA by generation. The trajectory exhibits epochs in the sense that plateaus in best fitness are punctuated by moments 
where a new type of strategy is discovered, leading to a new plateau.}
\label{fig:r2_best_fit}
\end{center}
\end{figure}
\begin{figure} [ht]
\begin{center}
\includegraphics[width=\linewidth]{foo.png}
\caption{Best fitness for $r = 3$ CA by generation. As in the case of $r = 2$ (fig.~\ref{fig:r2_best_fit}), the trajectory exhibits epochs. In contrast to $r = 2$, 
however, it takes longer or shorter or whatever if we see any differences.}
\label{fig:r3_best_fit}
\end{center}
\end{figure}

As noted, the epochs depicted in figures~\ref{fig:r2_best_fit} and \ref{fig:r3_best_fit} correspond to different dominant strategies. As reported in 
\cite{Mitchell:1994:ECA:186092.186116}, these strategies begin simple and become more nuanced over time. initially, since 50\% of each test set of ICs 
has $\rho_0 > 0.5$ (see section~\ref{sec:methods}), a CA that goes to all \texttt{1}s or all \texttt{0}s will be right 50\% of the time, which is better than never converging in the first place. Consequently, early generations are dominated by rule that adopt this strategy. As the number of generations increases, 
rules retain the initial strategy of always converging one way or the other, but begin to include `extreme' values of $\rho_0$ at the other end of the spectrum. 
As the generations progress, the rules become more able to accommodate less extreme values of $\rho_0$.

Let $\lambda$ be the proportion of \texttt{1}s in the binary representation of a rule (section~\ref{sec:methods}). Then the transitions just described are 
equivalent to shifting from rules with $\lambda = 0$ or $\lambda = 1$ to rules with $\lambda \approx \frac{1}{2}$. This transition is depicted in 
figure~\ref{fig:histogram}.

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{foo.png}
\caption{Frequency of different rules (as represented by $\lambda$) by generation. Over 50 runs of the GA, $\lambda$ values were collected at every 
fifth generation. Early generations are dominated by $\lambda \approx 1.0$ and $\lambda \approx 0.0$ indicating that most rules converged on all 
\texttt{0}s or all \texttt{1}s, regardless of $\rho_0$. By generation XXXXXX, .... yadda yadda yadda.}
\label{fig:histogram}
\end{center}
\end{figure}

Finally, note that each location in the lattice has a transient period in which its state may continue to flip before finally stabilizing (if at all; see figure~\ref{fig:waterfall}). One way to quantify this period is to count the number of times a given location changes state 
over the 200 iterations of a rule, given an initial condition. In order to visualize the relation between the length of a transient period and the fitness of a rule, 
we recorded the average length of the transients for each rule on each IC in the test set after each generation, and plotted this value against the fitness 
for that rule (figure~\ref{fig:transients}).

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{foo.png}
\caption{Average length of transients for each rule plotted against the fitness of that rule.}
\label{fig:transients}
\end{center}
\end{figure}

\subsection{Mutational robustness} \label{sec:2_2}

Mutational robustness occurs when changes in the genotype are phenotypically neutral: The genomic modification results in no significant change 
in the traits expressed, and hence no difference in fitness \cite{wagner_role_2012}. When a phenotype is robust in this way, it may be possible for the 
genome to move to a very different region of search space by accruing changes over multiple generations, increasing the breadth of the search for 
successful solutions without having to cross low-fitness boundaries.

If our CAs are mutationally robust, then the nearby neighbors of elite rules should themselves perform well. To assess whether 
this is the case, we selected XXXX elite rules from both the $r = 2$ and $r = 3$ runs, and randomly mutated each \textit{x} times, for $x = 1,2,3, ... 7$. 
For each \textit{x}, we tested the resulting rules against a set of ICs and recorded the fitness. The results are given in figure~\ref{fig:robustness}.

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{foo.png}
\caption{Testing for the mutational robustness of elite rules. XXXX elite rules from $r = 2$ and $r = 3$ GA runs were chosen and randomly mutated 1, 2, ... 7 
times. After each mutation, the resulting rules were tested against the same set of ICs, and the fitness recorded. As can be seen in the figure, 
rules are robust for approximately YYYY mutations, at which point fitness declines.}
\label{fig:robustness}
\end{center}
\end{figure}

\subsection{In search of a better CA} \label{sec:2_3}

As noted above (figure~\ref{fig:histogram}), some of the earliest successful strategies to emerge are those that (i) go to all \texttt{1}s or all \texttt{0}s by default, 
yet (ii) change their behavior for values of $\rho$ at the opposite extreme. For example, a rule may for the most part map every 
neighborhood to \texttt{0}, except for neighborhoods with many \texttt{1}s, so an IC with a high enough value of $\rho$ will 
`overwhelm' the default behavior of the rule. In such a rule, very IC with $\rho < 0.5$ is successfully classified, as are ICs with $\rho \approx 1.0$, but 
errors are made on those with $\rho \gtrapprox 0.5$.

Of course, the region around $\rho = 0.5$ is precisely the region we want to encourage the rules to deal with, yet under the fitness testing regime 
used for the experiments reported above, the `easy' cases (where $\rho \approx 1.0$ or $\rho \approx 0.0$) appear in testing sets  
with the same probability as any other IC for the entire GA run. As a result, CAs are still being rewarded for dealing with these easy cases long after their 
utility is exhausted.

To address this issue, we modified the GA so that the fitness gain for successfully classifying ICs is a function of its distance from $\rho = 0.5$: The 
closer to 0.5, the more a correct classification is worth. Furthermore, this function is adjusted depending on the current generation, so that at generation 1 
all ICs are worth the same amount of fitness regardless of their distance from $\rho = 0.5$, and the distance becomes increasingly more important as 
the generations progress.

To address this issue, we modified the GA so that IC sets are initially randomly constructed using a uniform distribution, but 
the distribution becomes increasingly normal, with mean of $\rho = 0.5$. This means that as the GA progresses, it becomes less likely that a 
set of ICs will include the easier cases, and more likely that harder cases will be included. 


