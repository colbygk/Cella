\section{Discussion} \label{discussion}

There are a number of interesting observations regarding the results reported above; here we survey these 
conclusions.

\subsection{On the difference between radius 2 and 3}

The size of the search space grows with the radius of a rule ($2^{32}$ for $r = 2$, and $2^{128}$ for $r = 3$), suggesting 
that searches may be more difficult for CAs with larger neighborhoods. However, a larger radius also means that the CA has more information 
to work with in deciding which state to transition to, suggesting that finding a solution may be easier for larger radii CAs despite the increased 
search size.

For both $r = 2$ and $r = 3$, we observe the pattern reported in \cite{Mitchell:1994:ECA:186092.186116}: Strategies begin simple and become 
more nuanced over time. We can see this progression in the series of histograms given in figures~\ref{fig:histogram_r2} 
and \ref{fig:histogram_r3}. In both cases, early populations (before generation 5) are dominated with rules that take an IC to all \texttt{0}s or 
all \texttt{1}s. This is a sort of `gambling' strategy because it `bets' that the correct answer 
is one way or the other. Interestingly, we also found rules that gambled in a different way: Oscillate $\rho$ back and forth from 1.0 to 0.0 in the hopes 
that, after 300 iterations, the final global state will be correct. Gambling is better than doing nothing, regardless of how you do it, and the GA 
was good at discovering this.

In both $r = 2$ and $r = 3$, $\lambda$ gradually moves towards 0.5: Rules retain the initial strategy of always converging one way or the other, but begin to include `extreme' values of $\rho_0$ at the other end of the spectrum. However, we also see a slight difference in the histograms for $r = 2$ and 
$r = 3$. In the former, there is the characteristic `dual peak' around $\lambda = 0.5$; this feature results from the fact that rules converge from both directions, 
i.e., from $\lambda \approx 0.0$ and $\lambda \approx 1.0$. But in the $r = 3$ case, we do not see this pattern; instead, we find a peak around 0.5 
with troughs on either side. We are not certain what is responsible for this distribution, but the absence of dual peaks could be an artifact of the 
bin size for the histograms.

Addressing the issue posed at the beginning of this section, figure~\ref{fig:r2_r3_rho} shows that the best of the $r = 3$ rules performs better than 
its $r = 2$ counterpart. It thus appears that the larger search space of the former was not an impediment to finding a fit solution, and the greater 
amount of information available to the rule was a benefit.

Finally, our analysis of the relation between fitness and transients in elite rules is difficult to interpret. On the one hand, it seems that elite rules 
eschew short transients. On the other hand, the results also show that elite rules can perform terribly when tested against large sets of ICs.  

\subsection{On mutational robustness}

In section~\ref{sec:2_2} we explored the fitness landscape surrounding the best-performing $r = 3$ rule discovered by our GA in an attempt to 
assess whether the rule exhibited mutational robustness, i.e., genomic modification without an impact to fitness. The fact that average fitness 
and its standard deviation decreases quickly (figure~\ref{fig:robustness}) shows that most mutations were deleterious to fitness. However, best-performing mutants actually did better for approximately a Hamming distance of 10 before starting to drop, and even then individuals occasionally performed 
well relative to the performance of the source rule.

This suggests that the landscape around the rule is `rocky' in the sense that there are some paths that maintain (or even increase) a high 
fitness, while most do not. But the rule is not `robustly robust` in the sense that any mutation is tolerated; there are some productive directions to go, but 
not every direction is productive.

\subsection{On the quest for a better solution}

ICs with extreme values of $\rho$ are easier to classify but interfere with the GA's ability to cope with harder cases at later generations. To address this, 
we implemented a `biased fitness' version of the GA that (i) makes the fitness benefit of correctly classifying an IC a function of its distance from 
$\rho = 0.5$ (the further the distance, the less the fitness benefit), and (ii) has this bias increase as the generation increases 
(see section~\ref{sec:methods}). In this way, the fitness function encourages the exploration of solutions to harder ICs as the GA proceeds.

Figure~\ref{fig:r2_r3_rho_biased} shows that the performance of the best biased $r = 2$ rule outperforms its unbiased counterpart, suggesting that 
the dynamic fitness function succeeded in focusing the search on solutions to harder cases. The figure also shows that the best biased $r = 3$ rule 
appears to do about as well as its unbiased counterpart; however, these rules were selected using 10k random ICs, and the biased $r = 3$ rule 
outperformed the unbiased version on that test set.


